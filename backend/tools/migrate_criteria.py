#!/usr/bin/env python3
"""
CR í”„ë¡œì íŠ¸ - í‰ê°€ ê¸°ì¤€ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” `current-criteria_v2_active.md` ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬
Two-Layer ì•„í‚¤í…ì²˜ì— í•„ìš”í•œ ë‘ ê°œì˜ JSON íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:
1. criteria_checklist.json: ì§„ë‹¨ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì§ˆë¬¸ + Red Flag)
2. ethics_library.json: ìœ¤ë¦¬ê·œë²” ì›ë¬¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì¸ìš© ì „ìš©)

Usage:
    python migrate_criteria.py

Output:
    ../data/criteria_checklist.json
    ../data/ethics_library.json
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any


def parse_criteria_markdown(md_content: str) -> Dict[str, Any]:
    """
    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
    """
    result = {
        "version": "2.0",
        "categories": []
    }
    
    lines = md_content.split('\n')
    
    current_category = None
    current_subcategory = None
    current_item = None
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # ## **1-1. ì§„ì‹¤ì„±ê³¼ ì •í™•ì„±** í˜•íƒœì˜ ì¹´í…Œê³ ë¦¬ í—¤ë”
        category_match = re.match(r'^##\s*\*\*(\d+-\d+)\.\s*(.+?)\*\*', line)
        if category_match:
            category_id = category_match.group(1)
            category_name = category_match.group(2).strip()
            current_category = {
                "id": category_id,
                "name": category_name,
                "subcategories": []
            }
            result["categories"].append(current_category)
            i += 1
            continue
        
        # ### **1-1-1. ì‚¬ì‹¤ ê²€ì¦ ë¶€ì‹¤** í˜•íƒœì˜ ì„œë¸Œì¹´í…Œê³ ë¦¬ í—¤ë”
        subcategory_match = re.match(r'^###\s*\*\*(\d+-\d+-\d+)\.\s*(.+?)\*\*', line)
        if subcategory_match and current_category:
            subcategory_id = subcategory_match.group(1)
            subcategory_name = subcategory_match.group(2).strip()
            current_subcategory = {
                "id": subcategory_id,
                "name": subcategory_name,
                "definition": "",
                "severity": "major",  # ê¸°ë³¸ê°’
                "diagnostic_questions": [],
                "red_flags": [],
                "ethics_code_refs": []
            }
            current_category["subcategories"].append(current_subcategory)
            current_item = None
            i += 1
            continue
        
        # - **í•­ëª©ëª…** : ì„¤ëª… í˜•íƒœì˜ í•­ëª©
        item_match = re.match(r'^-\s*\*\*(.+?)\*\*\s*[:ï¼š]?\s*(.*)$', line)
        if item_match and current_subcategory:
            item_name = item_match.group(1).strip()
            item_desc = item_match.group(2).strip()
            
            # ì´ í•­ëª©ì„ ì§„ë‹¨ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜
            question = generate_diagnostic_question(item_name, item_desc)
            if question:
                current_subcategory["diagnostic_questions"].append({
                    "q_id": f"{current_subcategory['id']}-{len(current_subcategory['diagnostic_questions']) + 1}",
                    "question": question,
                    "weight": 0.5
                })
            
            # Red Flag í‚¤ì›Œë“œ ì¶”ì¶œ
            red_flags = extract_red_flags(item_name, item_desc)
            current_subcategory["red_flags"].extend(red_flags)
            
            # definitionì´ ë¹„ì–´ìˆìœ¼ë©´ ì²« í•­ëª© ì„¤ëª…ìœ¼ë¡œ ì„¤ì •
            if not current_subcategory["definition"] and item_desc:
                current_subcategory["definition"] = item_desc[:200]
            
            i += 1
            continue
        
        # ì‹¬ê°ë„ ì„¤ì • (critical í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°)
        if current_subcategory and any(kw in line.lower() for kw in ['critical', 'ì‹¬ê°', 'ì¤‘ëŒ€']):
            current_subcategory["severity"] = "critical"
        
        i += 1
    
    # Red Flag ì¤‘ë³µ ì œê±°
    for category in result["categories"]:
        for sub in category["subcategories"]:
            sub["red_flags"] = list(set(sub["red_flags"]))[:10]  # ìƒìœ„ 10ê°œë§Œ ìœ ì§€
    
    return result


def generate_diagnostic_question(item_name: str, item_desc: str) -> str:
    """
    í•­ëª©ëª…ê³¼ ì„¤ëª…ì—ì„œ ì§„ë‹¨ ì§ˆë¬¸ ìƒì„±
    """
    # ì§ˆë¬¸ í˜•íƒœë¡œ ë³€í™˜
    question_patterns = {
        "ìµëª…": "ìµëª… ì·¨ì¬ì›ì„ ë‚¨ìš©í•˜ê±°ë‚˜ ì„¤ëª… ì—†ì´ ì‚¬ìš©í–ˆëŠ”ê°€?",
        "ë‹¨ì¼ ì·¨ì¬ì›": "ë‹¨ì¼ ì·¨ì¬ì›ì—ë§Œ ì˜ì¡´í•˜ì—¬ ë³´ë„í–ˆëŠ”ê°€?",
        "ë°˜ë¡ ": "ë¹„íŒ ëŒ€ìƒì—ê²Œ ë°˜ë¡  ê¸°íšŒë¥¼ ì¶©ë¶„íˆ ì œê³µí–ˆëŠ”ê°€?",
        "ë”°ì˜´í‘œ": "ì·¨ì¬ì› ë°œì–¸ì„ ë¬´ë¹„íŒì ìœ¼ë¡œ ì¸ìš©(ë”°ì˜´í‘œ ì €ë„ë¦¬ì¦˜)í–ˆëŠ”ê°€?",
        "ë³´ë„ìë£Œ": "ë³´ë„ìë£Œë¥¼ ê²€ì¦ ì—†ì´ ë°›ì•„ì“°ê¸°í–ˆëŠ”ê°€?",
        "ì¶”ì¸¡": "ì¶”ì¸¡ì´ë‚˜ ì˜ê²¬ì„ ì‚¬ì‹¤ì²˜ëŸ¼ í‘œí˜„í–ˆëŠ”ê°€?",
        "ê³¼ì¥": "ì‚¬ì‹¤ì„ ê³¼ì¥í•˜ê±°ë‚˜ ì™œê³¡í–ˆëŠ”ê°€?",
        "í¸í–¥": "íŠ¹ì • ì…ì¥ë§Œ ì¼ë°©ì ìœ¼ë¡œ ëŒ€ë³€í–ˆëŠ”ê°€?",
        "ë‚šì‹œ": "ë³¸ë¬¸ê³¼ ë‹¤ë¥¸ ìê·¹ì ì¸ ì œëª©ì„ ì‚¬ìš©í–ˆëŠ”ê°€?",
        "í†µê³„": "í†µê³„ë‚˜ ë°ì´í„°ë¥¼ ì˜¤ìš©í•˜ê±°ë‚˜ ì™œê³¡í–ˆëŠ”ê°€?",
        "í”¼í•´ì": "í”¼í•´ìì˜ ì¸ê¶Œì´ë‚˜ í”„ë¼ì´ë²„ì‹œë¥¼ ì¹¨í•´í–ˆëŠ”ê°€?",
        "ë¬´ì£„ì¶”ì •": "ë¬´ì£„ì¶”ì •ì˜ ì›ì¹™ì„ ìœ„ë°˜í–ˆëŠ”ê°€?",
        "ì°¨ë³„": "ì°¨ë³„ì ì´ê±°ë‚˜ í˜ì˜¤ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í–ˆëŠ”ê°€?",
    }
    
    for keyword, question in question_patterns.items():
        if keyword in item_name or keyword in item_desc:
            return question
    
    # ê¸°ë³¸ ì§ˆë¬¸ ìƒì„±
    if item_name:
        return f"'{item_name}' ë¬¸ì œê°€ ìˆëŠ”ê°€?"
    return None


def extract_red_flags(item_name: str, item_desc: str) -> List[str]:
    """
    í•­ëª©ì—ì„œ Red Flag í‚¤ì›Œë“œ ì¶”ì¶œ
    """
    red_flags = []
    combined = f"{item_name} {item_desc}"
    
    # ë”°ì˜´í‘œ ì•ˆì˜ ì˜ˆì‹œ í‘œí˜„ ì¶”ì¶œ
    quoted_patterns = re.findall(r'["\'\u201c\u201d\u2018\u2019]([^"\'\u201c\u201d\u2018\u2019]+)["\'\u201c\u201d\u2018\u2019]', combined)
    for pattern in quoted_patterns:
        if len(pattern) < 30 and len(pattern) > 3:  # ì ë‹¹í•œ ê¸¸ì´ì˜ í‘œí˜„ë§Œ
            red_flags.append(pattern.strip())
    
    # ì¼ë°˜ì ì¸ Red Flag íŒ¨í„´
    common_flags = [
        "ê´€ê³„ìì— ë”°ë¥´ë©´",
        "ë¡œ ì•Œë ¤ì¡Œë‹¤",
        "ë¡œ ì „í•´ì¡Œë‹¤",
        "ë¡œ ì „ë§ëœë‹¤",
        "ë¡œ ê´€ì¸¡ëœë‹¤",
        "ë¼ëŠ” í›„ë¬¸ì´ë‹¤",
        "ì†Œì‹í†µì— ì˜í•˜ë©´",
        "ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤",
        "ì—°ë½ì´ ë‹¿ì§€ ì•Šì•˜ë‹¤",
        "ë‹µë³€ì„ ê±°ë¶€í–ˆë‹¤",
        "ì¶©ê²©",
        "ê²½ì•…",
        "ë°œì¹µ",
        "ë¶„ë…¸",
        "í­íƒ„ ì„ ì–¸",
    ]
    
    for flag in common_flags:
        if flag in combined:
            red_flags.append(flag)
    
    return red_flags


def create_ethics_library() -> Dict[str, Any]:
    """
    ê¸°ë³¸ ìœ¤ë¦¬ê·œë²” ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„±
    (ì‹¤ì œ ê·œë²” ì „ë¬¸ì€ ë³„ë„ë¡œ ìˆ˜ì§‘ í•„ìš”)
    """
    return {
        "codes": {
            # ì‹ ë¬¸ìœ¤ë¦¬ì‹¤ì²œìš”ê°•
            "newspaper_ethics_practice_3_1": {
                "source": "ì‹ ë¬¸ìœ¤ë¦¬ì‹¤ì²œìš”ê°•",
                "article": "ì œ3ì¡°",
                "clause": "1í•­",
                "title": "ì‚¬ì‹¤ì˜ ë³´ë„",
                "full_text": "ê¸°ìëŠ” ì·¨ì¬ì— ì„í•´ í•­ìƒì„±ì‹¤í•˜ê²Œ ì‚¬ì‹¤ì„ íŒŒì•…í•´ì•¼ í•˜ë©°, ê·¸ ê²°ê³¼ë¥¼ ì •í™•íˆ ë³´ë„í•´ì•¼ í•œë‹¤.",
                "keywords": ["ì‚¬ì‹¤", "ì •í™•", "ë³´ë„"]
            },
            "newspaper_ethics_practice_3_2": {
                "source": "ì‹ ë¬¸ìœ¤ë¦¬ì‹¤ì²œìš”ê°•",
                "article": "ì œ3ì¡°",
                "clause": "2í•­",
                "title": "í™•ì¸ë³´ë„ ì›ì¹™",
                "full_text": "ë³´ë„ ê¸°ì‚¬ì˜ ì‚¬ì‹¤ ì—¬ë¶€ëŠ” í™•ì¸ë˜ì–´ì•¼ í•˜ë©°, í™•ì¸ë˜ì§€ ì•Šì€ ì‚¬ì‹¤ì„ ë³´ë„í•  ë•ŒëŠ” ê·¸ëŸ¬í•œ ì‚¬ì •ì„ ë°í˜€ì•¼ í•œë‹¤.",
                "keywords": ["í™•ì¸", "ì‚¬ì‹¤", "ê²€ì¦"]
            },
            "newspaper_ethics_practice_3_4": {
                "source": "ì‹ ë¬¸ìœ¤ë¦¬ì‹¤ì²œìš”ê°•",
                "article": "ì œ3ì¡°",
                "clause": "4í•­",
                "title": "ë¯¸í™•ì¸ë³´ë„ ëª…ì‹œ",
                "full_text": "ì¶œì²˜ê°€ ë¶„ëª…í•˜ì§€ ì•Šê±°ë‚˜ í™•ì¸ë˜ì§€ ì•Šì€ ì‚¬ì‹¤ì„ ë¶€ë“ì´ ë³´ë„í•  ë•ŒëŠ” ê·¸ ì‚¬ìœ ë¥¼ ë¶„ëª…íˆ ë°í˜€ì•¼ í•œë‹¤.",
                "keywords": ["ì¶œì²˜", "í™•ì¸", "ëª…ì‹œ"]
            },
            "newspaper_ethics_practice_3_9": {
                "source": "ì‹ ë¬¸ìœ¤ë¦¬ì‹¤ì²œìš”ê°•",
                "article": "ì œ3ì¡°",
                "clause": "9í•­",
                "title": "í”¼ì˜ì‚¬ì‹¤ ë³´ë„",
                "full_text": "ì‹ ë¬¸ì€ ë²”ì£„ì˜ í”¼ì˜ì ë˜ëŠ” í”¼ê³ ì¸ì— ëŒ€í•œ ë³´ë„ë¥¼ í•  ë•Œ ë¬´ì£„ì¶”ì •ì˜ ì›ì¹™ì„ ì¡´ì¤‘í•´ì•¼ í•˜ë©°, í”¼ì˜ì ì¸¡ì—ê²Œ í•´ëª…ì˜ ê¸°íšŒë¥¼ ì£¼ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•´ì•¼ í•œë‹¤.",
                "keywords": ["ë¬´ì£„ì¶”ì •", "í”¼ì˜ì", "í•´ëª…ê¸°íšŒ"]
            },
            "newspaper_ethics_practice_10_1": {
                "source": "ì‹ ë¬¸ìœ¤ë¦¬ì‹¤ì²œìš”ê°•",
                "article": "ì œ10ì¡°",
                "clause": "1í•­",
                "title": "ì œëª©ì˜ ì •í™•ì„±",
                "full_text": "ê¸°ì‚¬ì˜ ì œëª©ì€ ê¸°ì‚¬ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ë°˜ì˜í•´ì•¼ í•˜ë©°, ê³¼ì¥í•˜ê±°ë‚˜ ì™œê³¡í•´ì„œëŠ” ì•ˆ ëœë‹¤.",
                "keywords": ["ì œëª©", "ì •í™•", "ê³¼ì¥"]
            },
            # ì–¸ë¡ ìœ¤ë¦¬í—Œì¥
            "journalism_ethics_charter_1": {
                "source": "ì–¸ë¡ ìœ¤ë¦¬í—Œì¥",
                "article": "ì œ1ì¡°",
                "clause": None,
                "title": "ì§„ì‹¤ ë³´ë„",
                "full_text": "ì–¸ë¡ ì¸ì€ ëª¨ë“  ì •ë³´ë¥¼ ì„±ì‹¤í•˜ê²Œ ê²€ì¦í•˜ê³  ëª…í™•í•œ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ë„í•œë‹¤.",
                "keywords": ["ê²€ì¦", "ê·¼ê±°", "ì§„ì‹¤"]
            },
            "journalism_ethics_charter_2": {
                "source": "ì–¸ë¡ ìœ¤ë¦¬í—Œì¥",
                "article": "ì œ2ì¡°",
                "clause": None,
                "title": "ê³µì •í•œ ë³´ë„",
                "full_text": "ì–¸ë¡ ì¸ì€ ë‰´ìŠ¤ì™€ ì‚¬ì‹¤ì— ê·¼ê±°í•œ í•´ì„¤ì„ ì˜ê²¬ê³¼ ëª…ë°±í•˜ê²Œ ë¶„ë¦¬í•˜ì—¬ ë³´ë„í•œë‹¤.",
                "keywords": ["ê³µì •", "ì‚¬ì‹¤", "ì˜ê²¬ë¶„ë¦¬"]
            },
            "journalism_ethics_charter_4": {
                "source": "ì–¸ë¡ ìœ¤ë¦¬í—Œì¥",
                "article": "ì œ4ì¡°",
                "clause": None,
                "title": "ì¸ê¶Œ ë³´í˜¸",
                "full_text": "ì–¸ë¡ ì¸ì€ ì¸ê°„ì˜ ì¡´ì—„ì„±ê³¼ ê°œì¸ì˜ ëª…ì˜ˆë¥¼ ì¡´ì¤‘í•˜ê³  ì·¨ì¬ë³´ë„ ê³¼ì •ì—ì„œ ì‚¬ìƒí™œì˜ ììœ ì™€ ë¹„ë°€ì„ ì¹¨í•´í•˜ì§€ ì•ŠëŠ”ë‹¤.",
                "keywords": ["ì¸ê¶Œ", "ëª…ì˜ˆ", "ì‚¬ìƒí™œ"]
            },
            "journalism_ethics_charter_9": {
                "source": "ì–¸ë¡ ìœ¤ë¦¬í—Œì¥",
                "article": "ì œ9ì¡°",
                "clause": None,
                "title": "ë””ì§€í„¸ í™˜ê²½ì˜ ì±…ì„",
                "full_text": "ì–¸ë¡ ì¸ì€ ë””ì§€í„¸ í™˜ê²½ì—ì„œ í´ë¦­ ìœ ë„ë¥¼ ìœ„í•œ ì„ ì •ì  ì œëª©ì´ë‚˜ ê³¼ì¥ëœ í‘œí˜„ì„ ìì œí•œë‹¤.",
                "keywords": ["ë””ì§€í„¸", "í´ë¦­", "ì„ ì •ì "]
            },
            # í•œêµ­ê¸°ìí˜‘íšŒ ìœ¤ë¦¬ê°•ë ¹
            "kja_ethics_1": {
                "source": "í•œêµ­ê¸°ìí˜‘íšŒ ìœ¤ë¦¬ê°•ë ¹",
                "article": "ì œ1ì¡°",
                "clause": None,
                "title": "ì§„ì‹¤ ì¶”êµ¬",
                "full_text": "ê¸°ìëŠ” ì§„ì‹¤ì„ ì¶”êµ¬í•˜ë©°, ì •í™•í•˜ê³  ê³µì •í•˜ê²Œ ë³´ë„í•´ì•¼ í•œë‹¤.",
                "keywords": ["ì§„ì‹¤", "ì •í™•", "ê³µì •"]
            },
            "kja_ethics_3": {
                "source": "í•œêµ­ê¸°ìí˜‘íšŒ ìœ¤ë¦¬ê°•ë ¹",
                "article": "ì œ3ì¡°",
                "clause": None,
                "title": "ì·¨ì¬ì› ë³´í˜¸",
                "full_text": "ê¸°ìëŠ” ì·¨ì¬ì›ì˜ ì‹ ë¢°ë¥¼ ì €ë²„ë ¤ì„œëŠ” ì•ˆ ë˜ë©°, ìµëª… ë³´ë„ ì‹œì—ë„ ìµœì†Œí•œì˜ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤.",
                "keywords": ["ì·¨ì¬ì›", "ìµëª…", "ë³´í˜¸"]
            },
        }
    }


def map_ethics_codes(subcategory_id: str) -> List[str]:
    """
    ì„œë¸Œì¹´í…Œê³ ë¦¬ IDì— ë”°ë¼ ê´€ë ¨ ìœ¤ë¦¬ê·œë²” ID ë§¤í•‘
    """
    mappings = {
        "1-1-1": ["newspaper_ethics_practice_3_2", "newspaper_ethics_practice_3_4", "journalism_ethics_charter_1"],
        "1-1-2": ["newspaper_ethics_practice_3_1", "newspaper_ethics_practice_3_2"],
        "1-1-3": ["newspaper_ethics_practice_3_1"],
        "1-1-4": ["journalism_ethics_charter_2"],
        "1-1-5": ["newspaper_ethics_practice_3_1", "journalism_ethics_charter_1"],
        "1-2-1": ["kja_ethics_3", "newspaper_ethics_practice_3_4"],
        "1-2-2": ["journalism_ethics_charter_2"],
        "1-2-3": ["kja_ethics_1"],
        "1-3-1": ["journalism_ethics_charter_2"],
        "1-3-2": ["journalism_ethics_charter_2"],
        "1-3-3": ["journalism_ethics_charter_1"],
        "1-3-4": ["journalism_ethics_charter_2"],
        "1-3-5": ["journalism_ethics_charter_2"],
        "1-5-1": ["journalism_ethics_charter_4"],
        "1-5-2": ["journalism_ethics_charter_4"],
        "1-5-3": ["journalism_ethics_charter_4"],
        "1-5-4": ["newspaper_ethics_practice_3_9", "journalism_ethics_charter_4"],
        "1-7-1": ["journalism_ethics_charter_2"],
        "1-7-2": ["newspaper_ethics_practice_10_1", "journalism_ethics_charter_9"],
        "1-7-3": ["newspaper_ethics_practice_10_1", "journalism_ethics_charter_9"],
        "1-7-4": ["newspaper_ethics_practice_10_1"],
        "1-7-5": ["journalism_ethics_charter_4"],
        "1-7-6": ["journalism_ethics_charter_1"],
        "1-8-1": ["journalism_ethics_charter_9"],
        "1-8-2": ["journalism_ethics_charter_9"],
    }
    return mappings.get(subcategory_id, ["journalism_ethics_charter_1"])


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê²½ë¡œ ì„¤ì •
    script_dir = Path(__file__).parent
    docs_dir = script_dir.parent.parent / "docs"
    data_dir = script_dir.parent / "data"
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ
    criteria_md_path = docs_dir / "current-criteria_v2_active.md"
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    checklist_json_path = data_dir / "criteria_checklist.json"
    ethics_json_path = data_dir / "ethics_library.json"
    
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {criteria_md_path}")
    print(f"ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {data_dir}")
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°
    if not criteria_md_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {criteria_md_path}")
        return
    
    with open(criteria_md_path, 'r', encoding='utf-8') as f:
        md_content = f.read()
    
    print(f"âœ… ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë“œ ì™„ë£Œ ({len(md_content):,} bytes)")
    
    # 1. í‰ê°€ ê¸°ì¤€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
    print("\nğŸ”„ í‰ê°€ ê¸°ì¤€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    checklist = parse_criteria_markdown(md_content)
    
    # ìœ¤ë¦¬ê·œë²” ID ë§¤í•‘ ì¶”ê°€
    for category in checklist["categories"]:
        for sub in category["subcategories"]:
            sub["ethics_code_refs"] = map_ethics_codes(sub["id"])
    
    with open(checklist_json_path, 'w', encoding='utf-8') as f:
        json.dump(checklist, f, ensure_ascii=False, indent=2)
    
    # í†µê³„ ì¶œë ¥
    total_categories = len(checklist["categories"])
    total_subcategories = sum(len(cat["subcategories"]) for cat in checklist["categories"])
    total_questions = sum(
        len(sub["diagnostic_questions"])
        for cat in checklist["categories"]
        for sub in cat["subcategories"]
    )
    
    print(f"âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ:")
    print(f"   - ëŒ€ë¶„ë¥˜: {total_categories}ê°œ")
    print(f"   - ì†Œë¶„ë¥˜: {total_subcategories}ê°œ")
    print(f"   - ì§„ë‹¨ ì§ˆë¬¸: {total_questions}ê°œ")
    print(f"   - ì €ì¥ ìœ„ì¹˜: {checklist_json_path}")
    
    # 2. ìœ¤ë¦¬ê·œë²” ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„±
    print("\nğŸ”„ ìœ¤ë¦¬ê·œë²” ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„± ì¤‘...")
    ethics_library = create_ethics_library()
    
    with open(ethics_json_path, 'w', encoding='utf-8') as f:
        json.dump(ethics_library, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ìœ¤ë¦¬ê·œë²” ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„± ì™„ë£Œ:")
    print(f"   - ê·œë²” ì¡°í•­: {len(ethics_library['codes'])}ê°œ")
    print(f"   - ì €ì¥ ìœ„ì¹˜: {ethics_json_path}")
    
    print("\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
